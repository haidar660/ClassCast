# ML Need Justification

- Linking speech to board content manually is tedious and error-prone.
- Vision (OCR) + audio (ASR) + text (LLM fusion + TTS) align what is said with what is written, enabling search, Q&A, and audio synthesis.
- Multimodal models capture handwriting/math that captions ignore and let us translate/synthesize podcasts without losing context.
